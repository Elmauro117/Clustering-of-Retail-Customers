# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qKjd8yi9GhG7Vo70BTNqCV-AGBhQ-w_y
"""



import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.cm as cm

df = pd.read_csv("CustomerClean.csv")

df.head()

df = df.drop(["Unnamed: 0"], axis=1)

df.head()

from sklearn.cluster import KMeans

agrupador = KMeans(n_clusters = 3 )
agrupador.fit(df)
labels = agrupador.labels_
labels

## Let's see a plot that might tell us something.

import plotly.graph_objects as go

fig = go.Figure()
fig.add_trace(go.Scatter(x=df['Income'], y = df["TotalMntSpent"],
                                                        mode = 'markers',                      
                                                        marker = dict(color = agrupador.labels_.astype(np.float)),
                                                        text = labels))
fig.update_layout(title = 'Income X TotalMntSpent')
fig.update_xaxes(title = 'Income')
fig.update_yaxes(title = 'TotalMntSpent')
fig.show()

from scipy.spatial.distance import cdist

"""**Using CDIST method to find the optimal number of clusters**"""

K = range(1,10)
ssw = []

for k in K:
  agrupador = KMeans(n_clusters = k).fit(df)
  labels = agrupador.labels_
  centers = pd.DataFrame(agrupador.cluster_centers_)
  ssw_k = sum(np.min(cdist(df, agrupador.cluster_centers_, "euclidean"), axis = 1))
  ssw.append(ssw_k)

plt.plot(K, ssw, "bx-")
plt.xlabel("k")
plt.ylabel("SSw(k)")
plt.title("La técnica del codo para encontrar el k óptimo")
plt.show()

"""The plot shows that the K optimal is between 2 and 3

**Time to create the model and see the results**
"""

group = KMeans(n_clusters = 3 )
group.fit(df)
labels = group.labels_
labels

df["cluster"] = labels
df.groupby("cluster").describe()

df.groupby("cluster")["Income"].describe()

description = df.groupby("cluster")['Income', 'Recency', 'NumWebVisitsMonth', 'Client_Time', 'Kidhome',
       'Teenhome', 'Complain', 'Basic', 'Mid', 'Postgraduate', 'Couple', 'No',
       'Widow', 'Adult', 'Senior', 'SeniorPlus', 'TotalMntSpent',
       'TotalNumPurchases', 'Total_Acc_Cmp']
n_clients = description.size()
description = description.mean()
description['n_clients'] = n_clients
print(description)

"""## Intepretation

The cluster with the highest income has these characteristics:
1. Their Education is College and Upper
2. Have a couple, but are the less married of the bunch
3. Low Kidhome and Low Teenhome
4. Usually adults and seniors
5. Spend a lot
6. Accept the campaigns quite easily

The cluster with the second income has these characteristics:
1. Highest Educated
2. Have a couple, usually
3. Second largest spenders
4. High Teenhome

The cluster with the third income has these characteristics:
1. Greater number of children
2. Large n_clients
3. Low spenditure
4. Not so Well Educated
5. 2nd Highest Teenhome
"""

### Is a good practice to shufffle the data each time we run Kmeans
### Also is a Good practice to try to automatize and to define functions

def Run_many(df_Only_features_you_need, num):
  from sklearn.utils import shuffle
  n = range(1,num)
  for i in n:
    df=shuffle(df)
    group = KMeans(n_clusters = 3 )
    group.fit(df)
    labels = group.labels_
    my_list = list(df)
    df["cluster"] = labels
    description = df.groupby("cluster")[my_list]  ##ATTENTION: You shouldn't use my_list, use only the features you need, or clean it before
    n_clients = description.size()
    description = description.mean()
    description['n_clients'] = n_clients  ## You can change the name here depending on the problem
    print(description)

